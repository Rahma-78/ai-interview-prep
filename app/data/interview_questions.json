{
  "all_questions": [
    {
      "skill": "Natural Language Processing (NLP)",
      "questions": [
        "Explain the trade‑offs between aggressive preprocessing (e.g., tokenization, stop‑word removal, stemming) and feeding raw text directly into large pre‑trained language models. In which scenarios might heavy preprocessing hurt performance?",
        "Compare and contrast word‑level embeddings (Word2Vec, GloVe) with contextual embeddings from Transformers (e.g., BERT). How does the shift from static to dynamic representations affect downstream tasks such as NER or sentiment analysis?",
        "RNNs, LSTMs, and GRUs process sequences sequentially, limiting parallelism. Discuss how self‑attention in Transformers overcomes this limitation, and identify any new bottlenecks introduced by the attention mechanism.",
        "When fine‑tuning a pre‑trained Transformer for a low‑resource language, what strategies can mitigate data scarcity and bias introduced by the source corpora? Evaluate the pros and cons of transfer learning, multilingual pre‑training, and synthetic data generation.",
        "Design an end‑to‑end pipeline for processing noisy social‑media text (including slang, emojis, and misspellings). Which components would you prioritize for robustness, and how would you measure the impact of each preprocessing step on model performance?",
        "Discuss the ethical implications of bias in NLP models. How would you systematically detect, quantify, and remediate bias in a large language model used for automated hiring decisions?"
      ]
    },
    {
      "skill": "Computer Vision",
      "questions": [
        "Contrast the architectural choices of classic CNNs (e.g., VGG, ResNet) with modern vision transformers. What are the trade‑offs in terms of data efficiency, computational cost, and ability to capture long‑range spatial dependencies?",
        "In a real‑time object detection system deployed on an edge device, how would you balance model accuracy, latency, and power consumption? Discuss techniques such as model quantization, pruning, and knowledge distillation.",
        "Explain how data augmentation strategies differ for image classification versus instance segmentation. Which augmentations can inadvertently introduce label noise, and how would you mitigate that risk?",
        "When training a model for medical image analysis with limited annotated data, evaluate the merits of transfer learning from ImageNet versus self‑supervised pre‑training on domain‑specific unlabeled scans.",
        "Describe the challenges of handling occlusion and viewpoint variation in 3D object detection. What architectural or algorithmic modifications can improve robustness in autonomous driving scenarios?",
        "Outline a systematic approach to audit and reduce bias in a facial recognition system. Include dataset collection, model evaluation metrics, and post‑processing correction methods."
      ]
    },
    {
      "skill": "Large Language Models (LLMs)",
      "questions": [
        "Large language models exhibit scaling laws where performance improves with model size, data, and compute. Discuss the diminishing returns and practical constraints that arise when scaling beyond billions of parameters.",
        "Compare instruction‑tuning, reinforcement learning from human feedback (RLHF), and chain‑of‑thought prompting as methods to improve LLM alignment and reliability. What are the trade‑offs in terms of data requirements, training stability, and interpretability?",
        "Hallucination is a common failure mode in LLMs. Propose a multi‑pronged strategy—spanning architecture, training data curation, and post‑generation verification—to detect and reduce hallucinations in a question‑answering system.",
        "Tokenization schemes (e.g., BPE, WordPiece, Unigram) affect vocabulary size and handling of out‑of‑vocabulary words. How do these choices impact model efficiency and the ability to represent rare or multilingual tokens?",
        "Explain the privacy concerns associated with training LLMs on proprietary or user‑generated text. What technical safeguards (e.g., differential privacy, data filtering) can be employed, and what are their trade‑offs on model utility?",
        "Design an evaluation framework for measuring the real‑world utility of an LLM deployed as a customer‑support chatbot. Include metrics for relevance, factuality, latency, and user satisfaction, and discuss how you would perform continuous monitoring and improvement."
      ]
    }
  ]
}